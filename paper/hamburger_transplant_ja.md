# Hamburger Transplantation: Stitching Layerを用いたNeural Organ挿入による軽量な能力拡張

**著者**: Tatsuru Okada — Independent Researcher

---

## 概要（Abstract）

本論文は **Hamburger Transplantation** を提案する。これは、専門モデルから抽出した凍結MLP層（「臓器（organ）」）を、薄い学習可能なstitching layerを介して加算的に挿入することで、大規模言語モデル（LLM）の能力を拡張する軽量な手法である。従来のファインチューニングやLoRAとは異なり、本手法は**コンシューマー向けノートPC上でわずか30秒のトレーニング**（Apple Mシリーズ、GPUクラスタ不要）のみを必要とし、汎用テキストわずか200サンプルを使用し、残差接続によりベースモデルの元の能力を保持する。

推論organ（DeepSeek-R1由来）とコーディングorgan（Qwen2.5-Coder由来）をQwen2.5-7Bホストモデルに挿入することで、HumanEval性能が80.0%から**84.0%**（+4ポイント、プロンプト非依存）に向上することを実証した。日本語organを加えたトリプルorgan構成に拡張する過程で、系統的な**確信度バイアス（Confidence Bias）**問題を発見した：organ挿入が自然言語推論タスクにおける中立予測を抑制し、3クラス分布を2クラスに縮退させる。

この問題に対処するため、**Assistant Axis制約付きトレーニング**を提案する。これはモデルのアイデンティティ方向に沿った活性化の逸脱にペナルティを課す新しい2パストレーニング手順であり、バランスの取れた予測分布を回復させる。ホストの隠れ次元の2倍（7168 vs. 3584）までのモデルから日本語organを移植する包括的な異スケール実験を通じて、stitching layerが同等のパープレキシティ（5.91--6.26 vs. 5.45ベース）で**異アーキテクチャorgan移植**を可能にすることを実証する。制約強度（$\lambda$）とレイヤー範囲の系統的アブレーションにより、$\lambda{=}0.01$、$L{=}24$--$27$のスイートスポットを特定し、JNLIで**72.0%**を達成——ベースモデルの68.0%を上回りつつ、バランスの取れたクラス予測を維持する。5構成のクロスベンチマーク評価（MMLU-STEM、JCommonsenseQA、MBPP）により、organ挿入は対象能力を向上させる（MBPP +8pp、JComQA +10pp）一方、凍結パラメータにもかかわらずホスト知識を劣化させる**ソフト干渉**（MMLU-STEM -7.5pp）を引き起こすことを明らかにした。Axis制約はホスト知識を回復させるがorgan効果を抑制し、加算的移植における根本的なトレードオフを露呈する。全実験は単一のMacBook Pro（M4 Pro, 24GB）上で実施した。

---

## 1. はじめに（Introduction）

大規模言語モデル（LLM）は多様なタスクで顕著な能力を示してきたが、数学的推論やコード生成といった特定の能力を強化するには、通常、高コストなファインチューニング手続きが必要である。LoRA [Hu et al., 2022] のようなパラメータ効率的手法は計算要件を削減するが、それでもタスク固有のデータセット、GPUリソース、慎重なハイパーパラメータ調整を必要とする。完全なファインチューニングは既存能力の破壊的忘却（catastrophic forgetting）のリスクを伴う [Kirkpatrick et al., 2017]。

Neural Organ Transplantation（NOT）[Al-Zuraiqi, 2026] の最近の研究では、MLP層を専門モデルから抽出し、stitching layerで表現空間のギャップを橋渡ししてホストモデルに移植できることが示された。しかし、NOTアプローチは主に**層の置換**——ホスト層をドナー層で代替する——に焦点を当てており、ホストの元の能力を劣化させるリスクがある。

本研究では **Hamburger Transplantation** を提案する。これは**加算的挿入（additive insertion）**に基づく根本的に異なるアプローチである。層を置換するのではなく、既存のホスト層の間にorgan層を追加挿入し、残差接続で接続する：

$$\mathbf{h}' = \mathbf{h} + \alpha \cdot f_{\text{stitch-out}}(\text{MLP}_{\text{organ}}(f_{\text{stitch-in}}(\mathbf{h})))$$

ここで $\alpha$ は0.1で初期化された学習可能なスケールパラメータであり、organの寄与が小さく始まり、ホストモデルの動作が保持されることを保証する。

「Hamburger」という名前は建築的メタファーに由来する：organ層がホスト層の間にハンバーガーのパティのように挟まれ、stitching layerがギャップを橋渡しする調味料の役割を果たす。

### 主な貢献

1. **加算的Organ挿入**: 破壊的な層置換とは異なり、残差ベースのアプローチでベースモデルの能力を保持しつつ新しい能力を追加（§3）
2. **超軽量トレーニング**: Stitching layerはコンシューマーノートPC（Apple M4 Pro, 24GB RAM）上で200の汎用テキストサンプルを用いて**わずか30秒**のトレーニングのみ必要
3. **合成可能なマルチOrganアーキテクチャ**: 複数のorganを異なる層に積み重ね可能。デュアルorgan（HumanEvalで+4ポイント）およびトリプルorgan構成で実証（§5.1）
4. **確信度バイアスの発見**: organ挿入がNLIタスクにおける中立予測を系統的に抑制し、3クラス分布を2クラスに縮退させる障害モードを特定（§5.3）
5. **Assistant Axis制約付きトレーニング**: モデルのアイデンティティ方向に沿った活性化の逸脱にペナルティを課す新しい2パストレーニング手順。確信度バイアスを解消しつつorgan寄与を保持（§3.6）
6. **異スケール移植**: ホストの隠れ次元の2倍までのドナーからの移植を実現。InternLMおよびYiファミリーからの異アーキテクチャorganを含む（§5.5）
7. **制約アブレーション**: $\lambda \times$レイヤー範囲の相互作用の系統的研究により、ベースモデルを上回るスイートスポット（$\lambda{=}0.01$, L24--27）を発見（§5.7）

---

## 2. 関連研究（Related Work）

### 2.1 パラメータ効率的ファインチューニング

LoRA [Hu et al., 2022] とその派生手法（QLoRA [Dettmers et al., 2023]、DoRA [Liu et al., 2024]）は、低ランク重み更新の学習によりメモリ削減でのファインチューニングを可能にする。効果的ではあるが、これらの手法はタスク固有のトレーニングデータ（通常数千〜数百万サンプル）を必要とし、GPUハードウェア上で数時間〜数日のトレーニング時間を要する。本手法は汎用サンプル200個とCPU/MPSデバイス上で30秒のみ必要とする。

### 2.2 モデルマージと合成

モデルマージ技術 [Wortsman et al., 2022; Ilharco et al., 2023] は、複数のファインチューニング済みモデルの重みを結合する。TIES-Merging [Yadav et al., 2023] やDARE [Yu et al., 2024] はマージされたパラメータ間の干渉に対処する。重みマージとは異なり、本手法はコンポーネント間のアーキテクチャ的分離を保持し、破壊的干渉を回避する。

### 2.3 Mixture of Experts

Mixture-of-Experts（MoE）アーキテクチャ [Shazeer et al., 2017; Fedus et al., 2022] は入力を専門サブネットワークにルーティングする。概念的には関連するが、MoEモデルはゼロからのトレーニングまたは高コストなアップサイクリング [Komatsuzaki et al., 2023] を必要とする。本手法のorganは事前学習済み専門モデルから事後的に抽出され、最小限の適応のみ必要とする。

### 2.4 Neural Organ Transplantation

NOTフレームワーク [Al-Zuraiqi, 2026] は、ドナーモデルから機能的な「臓器」（MLP層）を抽出し、stitching layerを用いてホストモデルに移植する。本研究は3つの重要な点で異なる：(1) 層置換ではなく**加算的挿入**を使用し、ホスト能力を保持；(2) マルチorgan合成を実証；(3) 重要な1エポックトレーニング制約を特定。

### 2.5 Model Stitching

Model Stitching [Bansal et al., 2021; Csiszárik et al., 2021] は、異なるモデルの表現を接続するために線形変換を使用し、表現の類似性に関する洞察を提供する。本研究ではstitching layerをホストとドナーの表現間の実用的コネクタとして採用する。

---

## 3. 手法（Method）

### 3.1 概要

事前学習済みホストモデル $\mathcal{M}_H$（$L$ 個のtransformer層を持つ）と、1つ以上のドナーモデル $\{\mathcal{M}_{D_k}\}$ が与えられた場合、Hamburger Transplantationは3段階で進行する：

1. **Organ抽出**: ドナーモデルからMLP層をポータブルな「organ」として抽出
2. **Organ挿入**: 学習可能なstitching layerとともにorganをホスト層の間に挿入
3. **Stitchingトレーニング**: stitching layerのみ（全パラメータの0.3%）を汎用テキストで1エポック学習

### 3.2 Organ抽出

各ドナーモデル $\mathcal{M}_{D_k}$ から、SwiGLU [Shazeer, 2020] コンポーネントで構成される単一のtransformer MLPブロックを抽出する：

$$\text{Organ}_k = \{\mathbf{W}_{\text{gate}}^{(k)}, \mathbf{W}_{\text{up}}^{(k)}, \mathbf{W}_{\text{down}}^{(k)}\}$$

関連するレイヤー正規化パラメータと次元構成とともに。これらの重みは凍結され、トレーニング中に変更されることはない。

### 3.3 Stitchingアーキテクチャ

各organは2つの学習可能なstitching layerでラップされ、残差パスを介して接続される：

$$\mathbf{h}' = \mathbf{h} + \alpha \cdot S_{\text{out}}\left(\text{MLP}_{\text{organ}}\left(\text{LN}\left(S_{\text{in}}(\mathbf{h})\right)\right)\right)$$

ここで：
- $S_{\text{in}}: \mathbb{R}^{d_H} \to \mathbb{R}^{d_D}$：入力stitching layer（線形射影）
- $S_{\text{out}}: \mathbb{R}^{d_D} \to \mathbb{R}^{d_H}$：出力stitching layer
- $\text{LN}$：レイヤー正規化
- $\alpha$：0.1で初期化された学習可能なスケールパラメータ
- $d_H$ と $d_D$：ホストとドナーの隠れ次元

**初期化**: $d_H = d_D$（同一ファミリー移植）の場合、stitching layerは単位行列で初期化。$d_H \neq d_D$（異ファミリー）の場合、$\mathcal{N}(0, 0.02)$ で初期化。

残差接続は重要である：初期化時（トレーニング前）、organの寄与は小さく（$\alpha = 0.1$）、ホストモデルの動作が保持される。これはNOTの置換アプローチとは根本的に異なる。

### 3.4 マルチOrgan合成

複数のorganをホストネットワークの異なる位置に挿入可能：

$$\mathbf{h}_l' = \begin{cases} \mathbf{h}_l + \alpha_k \cdot \text{Organ}_k(\mathbf{h}_l) & \text{if layer } l \in \mathcal{P} \\ \mathbf{h}_l & \text{otherwise} \end{cases}$$

ここで $\mathcal{P}$ は挿入点の集合。挿入位置はネットワーク深度にorganを分散配置するよう選択した。これはtransformer層が深さとともにより抽象的な特徴をエンコードするという経験的知見——低層が構文的特徴を、高層が意味的表現を捉える [Tenney et al., 2019; Jawahar et al., 2019]——および中間～上位層がより高い冗長性を示し、加算的修正を受け入れやすいという知見 [Men et al., 2024] に基づく。トリプルorgan実験では以下を使用：
- **推論organ**（DeepSeek-R1）を第5層に（早い層）
- **コーディングorgan**（Qwen2.5-Coder）を第11層に（中間層）
- **日本語organ**（各種ドナー）を第17層に（後期中間層）

### 3.5 異スケール移植

ドナーの隠れ次元 $d_D$ がホストの次元 $d_H$ と異なる場合、stitching layer $S_{\text{in}}: \mathbb{R}^{d_H} \to \mathbb{R}^{d_D}$ と $S_{\text{out}}: \mathbb{R}^{d_D} \to \mathbb{R}^{d_H}$ が非自明な次元ブリッジを実行する。スケール比1.0倍から2.0倍までのドナーを評価する：

- Qwen2.5-14B-Instruct: $d_D{=}5120$（1.43倍）
- Qwen2.5-32B-Instruct: $d_D{=}5120$（1.43倍、より大きな中間次元）
- InternLM2.5-20B-Chat: $d_D{=}6144$（1.71倍、異なるアーキテクチャファミリー）
- Yi-1.5-34B-Chat: $d_D{=}7168$（2.00倍、異なるアーキテクチャファミリー）

### 3.6 Assistant Axis制約付きトレーニング

organ挿入が**確信度バイアス**を引き起こすことを発見した：モデルの出力分布が系統的にシフトし、分類タスクにおける不確実（中立）な予測を抑制する（§5.3）。これに対処するため、stitching layer学習時にモデルのアイデンティティ方向を保持するよう制約する**Assistant Axis制約付きトレーニング**を提案する。

**Axis抽出**: Representation Engineeringアプローチに従い、20種のロール（コンサルタント、アナリスト、詩人、反逆者など）と10の質問を用いて、モデルのデフォルト応答モードと多様なペルソナモードの平均活性化の差分から**アシスタント軸** $\mathbf{a} \in \mathbb{R}^{L \times d_H}$ を抽出する：

$$\mathbf{a}_l = \mathbb{E}_{\text{default}}[\mathbf{h}_l] - \mathbb{E}_{\text{persona}}[\mathbf{h}_l]$$

この軸は、モデルが「自分自身である」こと——キャリブレーションされたバランスの取れた応答行動——を特徴づける活性化空間の方向をエンコードする。

**制約付きトレーニング**: 拡張損失関数でstitchingパラメータを学習する：

$$\mathcal{L} = \mathcal{L}_{\text{LM}} + \lambda \sum_{l \in \mathcal{C}} \left\| \text{proj}_{\hat{\mathbf{a}}_l}(\mathbf{h}_l^{\text{organ}} - \mathbf{h}_l^{\text{base}}) \right\|^2$$

ここで $\hat{\mathbf{a}}_l = \mathbf{a}_l / \|\mathbf{a}_l\|$ はレイヤー $l$ での正規化軸、$\mathbf{h}_l^{\text{organ}}$ と $\mathbf{h}_l^{\text{base}}$ はレイヤー $l$ でのorgan有効/無効時の活性化、$\mathcal{C}$ は制約レイヤーの集合、$\lambda$ は制約強度を制御する。これにはorgan有効時と無効時（スケール $\alpha$ を一時的に0に設定）の2パスフォワードが必要である。

### 3.7 Stitching Layerトレーニング

**目的関数**: 標準的な言語モデリングロスを最小化：

$$\mathcal{L} = -\sum_{t=1}^{T} \log P(x_t | x_{<t}; \theta_S, \theta_H, \theta_O)$$

ここで $\theta_S$ はstitchingパラメータ（学習可能）、$\theta_H$ はホストパラメータ（凍結）、$\theta_O$ はorganパラメータ（凍結）。

**トレーニングプロトコル**: 本研究の重要な発見は、トレーニングは最小限であるべきということ：

| 項目 | 設定 |
|------|------|
| データ | WikiText-2から200サンプル（汎用テキスト） |
| エポック数 | **正確に1**（§5.8参照） |
| オプティマイザ | AdamW（lr=10⁻³、weight decay=0.01） |
| 勾配クリッピング | 最大ノルム1.0 |
| シーケンス長 | 128トークン |
| 学習可能パラメータ | organ1つあたり約25M（全体の0.3%） |

### アルゴリズム: Hamburger Transplantation

```
入力: ホストモデル M_H, ドナーorgan {O_k}, 挿入点 {l_k}, トレーニングデータ D
1: M_H と {O_k} の全パラメータを凍結
2: 各organ O_k について:
3:   S_in(k), S_out(k), α_k を初期化
4:   M_H の層 l_k にフォワードフックを登録
5: θ_S ← {S_in(k), S_out(k), α_k}_k    // 学習可能パラメータのみ
6: 各サンプル x ∈ D について:
7:   L(x; θ_S) を計算                    // 言語モデリングロス
8:   AdamWで θ_S を更新
9: organ付き拡張モデル M_H を返す
```

---

## 4. 実験（Experiments）

### 4.1 セットアップ

**ホストモデル**: Qwen2.5-7B-Instruct [Qwen Team, 2024] — 28 transformer層、隠れ次元3584、float16でロード。

**ドナーモデルとOrgan**:
- **Math Organ**: DeepSeek-R1-Distill-Qwen-7B [Guo et al., 2025] の第15層MLP（隠れ次元: 3584）。ホスト第5層の後に挿入。
- **Code Organ**: Qwen2.5-Coder-7B-Instruct [Hui et al., 2024] の第15層MLP（隠れ次元: 3584）。ホスト第11層の後に挿入。

全モデルは2025年1月にHuggingFace Hubから取得した。HuggingFace上のモデル重みはバージョン変更なしに更新される可能性があるため、厳密な再現には同一のチェックポイントスナップショットが必要である。

**ハードウェア**: 全実験はApple M4 Proチップと24GBユニファイドメモリを搭載したMacBook Pro上で実施。外部GPUやクラウドコンピューティングは使用していない。

**評価ベンチマーク**:
- **HumanEval** [Chen et al., 2021]: 50問のコード生成問題（seed=42）、グリーディデコーディング
- **JNLI**（JGLUE [Kurihara et al., 2022] より）: 日本語自然言語推論、50検証サンプル（seed=42）。3クラス: 含意（E=9）、矛盾（C=15）、中立（N=26）
- **JCommonsenseQA**（JGLUE より）: 日本語常識QA、50サンプル（seed=42）
- **パープレキシティ**: 英日混合コーパス、18サンプル

### 4.2 ベースラインと評価条件

1. **ベースモデル**: 未修正のQwen2.5-7B-Instruct
2. **直接挿入 (v1)**: stitching layerなしでorgan MLPを挿入
3. **デュアルOrgan**: Math@5 + Code@11 + 学習済みstitching
4. **トリプルOrgan**: Math@5 + Code@11 + Japanese@17（各種ドナー）
5. **トリプル + Axis**: トリプルorgan + Axis制約付きstitching学習

**公平な4条件比較**: HumanEvalでは完全交差実験を使用：2モデル（ベース / デュアルOrgan）× 2プロンプト（Simple / Reasoning）、全条件 `max_new_tokens=512` で統一。

---

## 5. 結果（Results）

### 5.1 主要結果: コード生成（HumanEval）

**表1: 開発過程での結果**（10問サブセット、seed=42）

| モデル | Pass@1 | トレーニング時間 | データ数 | ハードウェア |
|--------|--------|----------------|---------|------------|
| ベースモデル (Qwen2.5-7B) | 8/10 (80%) | --- | --- | --- |
| 直接挿入 (v1) | 2/10 (20%) | 0 | 0 | --- |
| シングルOrgan (Code, 3ep) | 5/10 (50%) | 90秒 | 500 code | MPS |
| シングルOrgan (Code, 1ep) | 8/10 (80%) | 30秒 | 200 wiki | MPS |

**表2: 公平な4条件比較**（HumanEval 50問、seed=42、max_new_tokens=512統一。トレーニング時間: Apple M4 Proで60秒）

|  | Simpleプロンプト | Reasoningプロンプト | Δ (プロンプト) |
|---|---|---|---|
| ベースモデル | 40/50 (80.0%) | 39/50 (78.0%) | -1 |
| **デュアルOrgan** | **42/50 (84.0%)** | 41/50 (82.0%) | -1 |
| Δ (Organ) | **+2 (+4.0%)** | **+2 (+4.0%)** | |

**効果分解**: organ効果はプロンプト種別に関わらず一貫して+2問（+4.0%）。reasoningプロンプト（「Think step by step」）は両モデルで1問減少（-2.0%）を引き起こし、コード生成タスクでは逆効果であることを示す。重要なのは、organ効果とプロンプト効果の間に交互作用がないこと：organ挿入による改善は**プロンプト非依存**である。

デュアルorganモデルはHumanEvalで**84.0%**（42/50）を達成し、ベースモデルの80.0%（40/50）を+4ポイント上回った。総トレーニング時間はわずか60秒。

**マルチシード頑健性検証**: 単一seedの限定的な統計検出力に対処するため、3つのseed（42, 123, 456）で4条件ベンチマークを反復した（表2b）。

**表2b: マルチシードHumanEval結果**（seed毎に50問、計150評価。Δ = Dual − Base）

| Seed | Base(S) | Base(R) | Dual(S) | Dual(R) | Δ(S) | Δ(R) |
|------|---------|---------|---------|---------|------|------|
| 42 | 40/50 (80%) | 39/50 (78%) | 42/50 (84%) | 42/50 (84%) | +2 | +3 |
| 123 | 44/50 (88%) | 38/50 (76%) | 43/50 (86%) | 39/50 (78%) | -1 | +1 |
| 456 | 40/50 (80%) | 38/50 (76%) | 41/50 (82%) | 38/50 (76%) | +1 | ±0 |
| **平均** | **82.7%** | **76.7%** | **84.0%** | **79.3%** | **+1.3pp** | **+2.7pp** |

3 seed全体で、Simpleプロンプトのorgan効果は平均+1.3pp（95% CI: [−2.0, +4.0]）、Reasoningプロンプトでは+2.7pp（95% CI: [+0.0, +6.0]）。プールされた片側二項検定はp=0.38であり、α=0.05での有意水準には達しない。しかし効果の方向は**一貫して非負**：6つのseed×プロンプト組み合わせのうち5つが改善を示し、1つのみが-1の回帰を示す。この方向的一貫性は、統計的に確認するにはより大きなnが必要であるが、実在する小さな効果を示唆する。

### 5.2 トリプルOrgan: 日本語能力の追加

トリプルorgan構成（Math@5 + Code@11 + Japanese@17）に拡張し、日本語NLPベンチマークで評価する（表3）。

**表3: 日本語NLPベンチマーク結果**（各50サンプル、seed=42。PPLは18サンプル混合コーパスで測定）

| 構成 | JCom.QA | JNLI | PPL | Organ数 |
|------|---------|------|-----|---------|
| ベースモデル | 86.0% | **68.0%** | **5.45** | 0 |
| DUAL (Math+Code) | 90.0% | 62.0% | 5.81 | 2 |
| TRIPLE (8B Japanese) | **94.0%** | 42.0% | 6.48 | 3 |

顕著なパターンが浮かび上がる：JCommonsenseQAはorgan数に伴い単調に**改善**（86% → 90% → 94%）する一方、JNLIは**劣化**（68% → 62% → 42%）する。この非対称性は、organ挿入が知識検索タスクには選択的に有益だが、キャリブレーションされた不確実性を必要とするタスクには有害であることを明らかにする。

### 5.3 確信度バイアス問題

JNLI予測分布を詳細に検証し、根本原因を特定する（表4）。

**表4: JNLI予測分布に見る確信度バイアス**（正解分布: E=9, C=15, N=26）

| 構成 | 正解率 | E | C | N | N不足 |
|------|--------|---|---|---|-------|
| ベースモデル | 68.0% | 14 | 10 | 26 | 0 |
| Mathのみ @5 | 64.0% | 18 | 17 | 15 | -11 |
| Codeのみ @11 | 68.0% | 19 | 11 | 20 | -6 |
| DUAL (Math+Code) | 62.0% | 20 | 18 | 12 | -14 |
| Japanese @17 (8B) | 48.0% | 25 | 21 | 4 | -22 |
| TRIPLE | 42.0% | 34 | 16 | **0** | -26 |
| Math+Japanese | 42.0% | 27 | 23 | **0** | -26 |
| Code+Japanese | 38.0% | 33 | 17 | **0** | -26 |

**主要な知見**: (1) 各organが中立予測の抑制に加算的に寄与する。(2) 日本語organを含む組み合わせは中立予測を完全に消失させる（N=0）。(3) バイアスは**系統的**である：正解分布に関わらず、organはモデルを確信的（含意/矛盾）な予測に押しやる。筆者はこれを**確信度バイアス**と呼ぶ——organ挿入がモデルのキャリブレーションされた不確実性を破壊し、「わからない」と表明する能力を奪う。

この発見はより広い含意を持つ：加算的organ挿入は、ホストの**能力**を保持する一方で、標準的なベンチマークでは捕捉されない形でその**判定キャリブレーション**を変化させうる。

**キャリブレーション指標.** この分布シフトをクラス数を超えて定量化するため、クラスレベルのキャリブレーション指標を算出する（表4b）。

**表4b: 選択されたJNLI条件のキャリブレーション指標**（CCE: クラスキャリブレーション誤差 = 各クラスの|予測頻度 - 正解頻度|の平均。JSD: 予測分布と正解クラス分布間のJensen-Shannonダイバージェンス）

| 構成 | 精度 | CCE | Brier | JSD |
|------|------|-----|-------|-----|
| ベースモデル | 68.0% | 0.107 | 0.640 | 0.013 |
| DUAL (Math+Code) | 62.0% | 0.187 | 0.760 | 0.049 |
| TRIPLE | 42.0% | 0.347 | 1.160 | 0.258 |
| **λ=0.01, L24-27** | **72.0%** | **0.013** | **0.560** | **0.001** |

スイートスポット制約（$\lambda{=}0.01$, L24-27）は全指標で**最低**のキャリブレーション誤差を達成する——ベースモデルよりも低い（CCE: 0.013 vs. 0.107; JSD: 0.001 vs. 0.013）——同時に**最高**の精度（72.0%）を達成。これはAxis制約がキャリブレーションを単に回復するだけでなく、誤キャリブレーションを引き起こすorgan寄与をフィルタリングしつつ有益な寄与を保持することで、積極的に**改善**することを示す。

### 5.4 異スケール移植

確信度バイアスが、異なる隠れ次元を持つ大型ドナーモデルからの日本語organでも持続するかを評価する。

**表5: 異スケールTRIPLE organ結果**（JNLI およびパープレキシティ。全て標準stitching、Axis制約なし）

| 日本語ドナー | $d_D$ | スケール | JNLI | E | C | N | PPL |
|-------------|--------|---------|------|---|---|---|-----|
| Qwen3-8B（同一ファミリー） | 3584 | 1.0倍 | 42.0% | 34 | 16 | 0 | 6.48 |
| Qwen2.5-14B | 5120 | 1.43倍 | 56.0% | 23 | 18 | 9 | 6.26 |
| Qwen2.5-32B | 5120 | 1.43倍 | 62.0% | 21 | 17 | 12 | 5.91 |
| InternLM2.5-20B | 6144 | 1.71倍 | 62.0% | 21 | 17 | 12 | 5.97 |
| Yi-1.5-34B | 7168 | 2.00倍 | 56.0% | 19 | 21 | 10 | 6.15 |

**知見**: (1) 大型ドナーは中立予測を部分的に回復させる（N=0 → 9--12）。異スケールstitching layerがより保守的なマッピングを学習することを示唆する。(2) パープレキシティは競争力を維持：32Bドナーで5.91（vs. ベース5.45）を達成し、stitching layerが1.43倍の次元ギャップを成功裏に橋渡しすることを実証。(3) 確信度バイアスは**軽減**されるが**解消**されない——全構成で正解分布（N=26）に対し中立を過少予測。

#### 5.4.1 失敗事例: 72B Organ（2.29倍）

異スケール移植の上限を探るため、Qwen2.5-72B-Instruct（$d_D{=}8192$、ホスト次元の2.29倍）からのorgan移植を試みた。この実験は壊滅的に失敗した。

**72B Organ — スケール値と出力品質**

| スケール $\alpha$ | 品質 | 症状 |
|-------------------|------|------|
| 0.1 | 劣化 | 繰り返しループ |
| 0.3 | 崩壊 | 数字の羅列（「0000...」） |
| 0.5 | 崩壊 | 記号の無限繰り返し（「$,$,$...」） |
| 1.0 | 崩壊 | 内部トークン漏出（Javaメソッド名、中国語トークン） |

$\alpha{=}1.0$では、72Bモデルの内部表現の断片——Javaメソッド名（`.moveToNext`）や中国語トークン——が漏出し、stitching layerが高次元空間の正しいマッピングに失敗していることを示す。エポック数を3に増加させるとロスは低下（1.83→1.49）するが出力品質はさらに悪化（ハルシネーション発生）。挿入位置の変更（第5層、第17層、第21層）も問題を解決しなかった。

Yi-1.5-34B（2.00倍、$d_D{=}7168$）の成功と合わせると、**線形stitchingの実用的な次元比率上限は2.0倍〜2.29倍の間**に存在することが確立される。

### 5.5 Assistant Axis制約: 確信度バイアスの解消

Axis制約付きトレーニング手順（§3.6）をTRIPLE構成に適用する。

#### 5.5.1 ラムダスイープ（8B organ, L22--27）

**表6: Axis制約 $\lambda$ スイープ**（TRIPLE 8B、制約レイヤー L22--27）

| 制約 | JNLI | E | C | N | 所見 |
|------|------|---|---|---|------|
| 制約なし | 42.0% | 34 | 16 | 0 | 完全なバイアス |
| Axis v1（挿入レイヤー） | 38.0% | 39 | 11 | 0 | 悪化 |
| Axis v2 ($\lambda{=}0.01$) | 62.0% | 18 | 19 | 13 | 部分的回復 |
| Axis v2 ($\lambda{=}0.05$) | 68.0% | 15 | 12 | 23 | ベースに近い |
| Axis v2 ($\lambda{=}0.1$) | **70.0%** | 14 | 11 | 25 | **ベースを超過** |

$\lambda{=}0.1$ において、Axis制約は中立予測を回復させる（N=25 vs. 正解=26）だけでなく、**70.0%の精度を達成し、ベースモデルの68.0%を超過**する。制約は確信度バイアスを効果的に除去しつつ、有益なorganの寄与を残す。

#### 5.5.2 異スケール + Axis制約

最適な $\lambda{=}0.1$ を全異スケールドナーに適用する（表7）。

**表7: 異スケールTRIPLE + Axis制約**（$\lambda{=}0.1$, L22--27、JNLI）

| 日本語ドナー | スケール | JNLI | E | C | N |
|-------------|---------|------|---|---|---|
| ベース（organ なし） | --- | 68.0% | 14 | 10 | 26 |
| Qwen3-8B | 1.0倍 | **70.0%** | 14 | 11 | 25 |
| Qwen2.5-14B | 1.43倍 | 68.0% | 14 | 10 | 26 |
| Qwen2.5-32B | 1.43倍 | 68.0% | 14 | 10 | 26 |
| InternLM2.5-20B | 1.71倍 | 68.0% | 14 | 10 | 26 |
| Yi-1.5-34B | 2.00倍 | **70.0%** | 14 | 11 | 25 |

$\lambda{=}0.1$ において、全異スケール構成がベースレベル以上の精度に収束する。14B、32B、20Bドナーはベースモデルと**完全に同一**の分布を生成し、制約がこれらのorgan寄与を完全に抑制していることを示す。8Bと34Bドナーは70.0%を達成し、stitching幾何学の微妙な差異が制約を通じてわずかなorgan寄与を通過させることを示唆する。

### 5.6 アブレーション: 制約強度 × レイヤー範囲

異スケール結果は $\lambda{=}0.1$ がorganを過剰に制約する可能性を示唆する。$\lambda \in \{0.001, 0.01, 0.1\}$ と制約レイヤー $\mathcal{C} \in \{\text{L22--27}, \text{L24--27}, \text{L26--27}\}$ を系統的にアブレーションする（Qwen2.5-14Bドナー、表8）。

**表8: アブレーション**: $\lambda \times$ 制約レイヤー（TRIPLE 14B、JNLI。正解分布: E=9, C=15, N=26）

| $\lambda$ | レイヤー | JNLI | E | C | N | Δベース |
|-----------|---------|------|---|---|---|---------|
| *ベースモデル（organなし）* | | 68.0% | 14 | 10 | 26 | --- |
| 0.1 | L22--27 | 68.0% | 14 | 10 | 26 | ±0 |
| 0.1 | L26--27 | 68.0% | 14 | 10 | 26 | ±0 |
| 0.01 | L26--27 | 70.0% | 14 | 12 | 24 | +2.0 |
| **0.01** | **L24--27** | **72.0%** | **14** | **15** | **21** | **+4.0** |
| 0.01 | L22--27 | 64.0% | 17 | 17 | 16 | -4.0 |
| 0.001 | L26--27 | 64.0% | 17 | 17 | 16 | -4.0 |
| 0.001 | L22--27 | 50.0% | 18 | 27 | 5 | -18.0 |
| *制約なし* | | 42.0% | 34 | 16 | 0 | -26.0 |

**アブレーションの主要な知見**:

1. **$\lambda{=}0.01$, L24--27のスイートスポット**: 最高のJNLI精度（72.0%、ベースから+4ポイント）を達成し、C=15が正解分布と完全に一致。制約は確信度バイアスを防止するのに十分だが、有益なorgan寄与を許容するのに十分緩い。
2. **$\lambda{=}0.1$はorganを完全に抑制**: 全 $\lambda{=}0.1$ 条件がベースモデルと同一の分布を生成し、この制約が強すぎることを確認。
3. **レイヤー範囲が重要**: $\lambda{=}0.01$において、L26--27（70%） > L24--27（72%） > L22--27（64%）。レイヤーを多く制約しすぎると、制約不十分な初期レイヤーを通じてバイアスが再導入される。
4. **明確な勾配**: 制約が弱まるにつれ（$\lambda$: 0.1 → 0.01 → 0.001 → 0）、精度は単調に劣化（68 → 64 → 50 → 42%）し、中立予測が崩壊（26 → 16 → 5 → 0）する。

### 5.7 1エポック現象

最も驚くべき発見は、**1エポックを超えるトレーニングが下流タスクの性能を劣化させる**こと。トレーニングロスは単調に減少するにもかかわらず（表9）。

**表9: トレーニングエポックがstitching layer品質に与える影響**（Code Organ, HumanEval 10問）

| トレーニングデータ | エポック数 | トレーニングロス | HumanEval |
|-------------------|----------|----------------|-----------|
| WikiText（汎用） | 1 | 3.17 | 7/10 (70%) |
| Code（ドメイン固有） | 1 | 0.98 | **8/10 (80%)** |
| Code（ドメイン固有） | 3 | 0.81 | 5/10 (50%) |
| Mixed（wiki+code） | 2 | 1.72 | 7/10 (70%) |

この直感に反する結果は、stitching layerが粗い表現アライメントのみを学習すればよいことを示唆する——ホストとドナー空間間の基本的な線形マッピング。追加のトレーニングにより、stitching layerはトレーニング分布に過学習し、organの寄与を歪めて下流タスクの性能を損なう。

**仮説**: 最適なstitching layerは、同一ファミリー移植では近恒等変換を、異ファミリー移植では単純な回転・スケーリングを近似すると推測する。過度のトレーニングは、忠実な表現の橋渡しを維持するのではなく、トレーニングデータの特定パターンを「利用」するように学習してしまう。

### 5.8 トレーニングデータ: 汎用 vs ドメイン固有

関連する発見として、**汎用トレーニングデータ（WikiText）がドメイン固有データと同等以上の性能**を示す（表10）。

**表10: トレーニングデータドメインがstitching品質に与える影響**（Code Organ, 1エポック）

| トレーニングデータ | トレーニングロス | HumanEval (10問) |
|-------------------|----------------|-----------------|
| WikiText（汎用） | 3.17 | 7/10 (70%) |
| CodeParrot（ドメイン固有） | 0.98 | 8/10 (80%) |
| Mixed（50/50） | 1.87 | 7/10 (70%) |

これは、stitching layerが主にタスク固有の特徴ではなく表現アライメントを学習するという仮説を支持する。トレーニングデータの選択よりもイテレーション数の方が重要である。

### 5.9 アブレーション: Organ配置

**表11: Organ構成比較**（10問サブセット）

| 構成 | HumanEval (10問) |
|------|------------------|
| Codeのみ (第11層) | 8/10 |
| Mathのみ (第5層) | ---† |
| デュアル (Math@5 + Code@11) | 8/10 |

†Math organのみではHumanEval（コード中心ベンチマーク）での評価は未実施。

10問サブセットではシングルとデュアルOrganの差は現れないが、50問の公平な4条件比較（表2）においてデュアルOrganの一貫した+2問の改善が確認された。

### 5.10 プロンプト効果の分離

4条件比較の重要な発見は、**reasoningプロンプト（「Think step by step」）はHumanEval性能を改善しない**こと：

- ベースモデル: Simple 80.0% → Reasoning 78.0%（-2.0%）
- デュアルOrgan: Simple 84.0% → Reasoning 82.0%（-2.0%）

これは、reasoningプロンプトがコード生成タスクでは余分な思考を生成し、実装の正確性を損なうことを示唆する。一方、organ効果はプロンプト種別に依存せず一貫して+4.0%であり、**organ挿入がプロンプトエンジニアリングとは独立した、表現レベルの改善**を提供することを意味する。

### 5.11 数値安定性

stitching layerなしの直接organ挿入は、異ファミリー移植で壊滅的な数値不安定性を引き起こす：

**表12: stitching layerの有無による数値安定性**

| Organソース | ファミリー一致 | 直接 (v1) | Stitched (v2) |
|-------------|---------------|-----------|---------------|
| Qwen2.5-Coder-7B | 同一 (Qwen2.5) | 部分的nan/inf | 安定 |
| DeepSeek-R1-Distill-Qwen | 関連 | nan/inf | 安定 |
| Qwen3-8B | 異なる | nan/inf | 安定 |

Stitching layerは、隠れ次元が異なる場合（例：3584 → 4096）でも、表現空間間のマッピングを学習することで数値不安定性を完全に解消する。

### 5.12 計算コスト

**表13: 能力拡張手法の計算コスト比較**

| 手法 | トレーニング時間 | 必要データ | ハードウェア | 忘却リスク |
|------|----------------|-----------|------------|-----------|
| 完全ファインチューニング | 数時間〜数日 | 10K〜1M+ | A100 GPU | 高 |
| LoRA | 1〜12時間 | 1K〜100K | GPU | 中 |
| QLoRA | 30分〜6時間 | 1K〜100K | コンシューマーGPU | 中 |
| **本手法** | **30〜60秒** | **200** | **MacBook (MPS)** | **設計上なし*** |

*ベースモデル凍結の加算的アーキテクチャにより、元の重みを構造的に保持。ただし、加算的organ寄与によるソフト干渉（MMLU-STEM -7.5pp、§5.13参照）および判定キャリブレーションの変化（§5.3参照）が発生しうる。

### 5.13 クロスベンチマーク評価

コード生成以外でのOrgan効果を評価するため、5つのモデル構成を3つのベンチマークで評価した：MMLU-STEM（8科目×25問=200問、選択型）、JCommonsenseQA（50問、選択型）、MBPP（50問、コード生成型）。全評価はseed=42で同一の問題サブセットを使用。なお、JCommonsenseQAのスコアは表3と若干異なるが、これはランダムサンプルの差異および生成ベースではなくlog-probabilityスコアリングを使用したためである。

**表14: クロスベンチマーク評価（Δはベースからの変化）**

| 構成 | MMLU-STEM | JComQA | MBPP |
|------|-----------|--------|------|
| Base (Qwen2.5-7B) | 58.0% | 82.0% | 66.0% |
| Dual (Math+Code) | 53.5% (-4.5) | 88.0% (+6.0) | **74.0%** (+8.0) |
| Triple (Math+Code+JP) | 50.5% (-7.5) | **92.0%** (+10.0) | 66.0% (±0.0) |
| Triple + Axis (λ=0.01) | **58.5%** (+0.5) | 78.0% (-4.0) | 66.0% (±0.0) |
| Triple + 14B Axis | 56.5% (-1.5) | 78.0% (-4.0) | 64.0% (-2.0) |

3つのパターンが明らかになった：

**(1) Organは対象能力を向上させる。** Code OrganはMBPPで+8pp（66→74%）を達成し、移植された専門知識が関連ベンチマークに転移することを確認した。Japanese OrganはTriple構成でJCommonsenseQAを82%から92%に押し上げ、+10ppの大幅な向上を示した。

**(2) マルチOrgan挿入はホスト知識を劣化させる。** MMLU-STEMが段階的に低下：Base 58.0% → Dual 53.5% → Triple 50.5%。ベースモデルは凍結されているにもかかわらず、加算的なOrgan寄与がホストの内部表現を十分に摂動させ、知識集約型タスクの性能を低下させた。これは**ソフト干渉**の一形態である。

**(3) Axis制約はホスト知識を回復させるが、Organ効果を抑制する。** Triple+AxisはMMLU-STEMをベースライン水準に回復（58.5%）させるが、JCommonsenseQAはベースモデルを下回る（78% vs 82%）。制約がOrgan寄与をホストの同一性軸に沿って「中和」し、知識保持を回復させる代わりに、Organが提供する能力向上そのものを制限してしまう。これは加算的移植における根本的なトレードオフを示している。

---

## 6. 議論（Discussion）

### 6.1 なぜ1エポックトレーニングが機能するのか？

stitching layerは**特徴学習器**ではなく**表現アダプター**として機能すると仮説を立てる。その役割は、ホストの隠れ状態をorganの表現空間に（そしてその逆に）線形マッピングすることであり、新しい特徴を学習することではない。このマッピングは比較的低複雑度——おおよそ回転とスケーリング——であり、最小限のデータから学習可能である。追加のトレーニングはstitching layerをこのアライメントの役割を超えさせ、汎化を損なう分布固有のバイアスをエンコードさせてしまう。

これはNLPにおけるProcrustes整合 [Schönemann, 1966] に類似している：2つの埋め込み空間の整合には線形変換のみが必要であり、少数のアンカーポイントから推定可能である。

### 6.2 加算的 vs 置換型移植

残差接続 $\mathbf{h}' = \mathbf{h} + \alpha \cdot \text{organ}(\mathbf{h})$ は本アプローチの基盤である。以下を提供する：

1. **優雅な劣化（graceful degradation）**: organが無益な出力を生成しても、残差により元の信号が通過
2. **能力の保持**: ベースモデルの動作がデフォルトとして維持
3. **合成可能性**: 複数のorganが破壊的干渉なく加算的に寄与

しかし、確信度バイアスの発見（§5.3）は、「能力の保持」が以前理解されていたよりも複雑であることを明らかにする：ホストの**知識**は保持されるが、その**判定キャリブレーション**は破壊されうる。残差接続は能力保持を保証するが、分布保持は保証しない。

### 6.3 確信度バイアスの理解

確信度バイアスは、organ MLPが専門モデルで訓練されたため、確信的な予測に対する事前分布をエンコードしていることに起因すると仮説を立てる。自然言語推論において、ベースモデルの中立予測は活性化強度の微妙なバランスに依存する——モデルは「決定しないことを決定」しなければならない。organの寄与は、いかに小さくとも（$\alpha{=}0.1$）、含意や矛盾を中立よりも有利にする方向に活性化を摂動させる。この効果は加算的である：各organが独立に分布を偏らせ、マルチorgan構成でより強いバイアスを示す理由を説明する（表4）。

Assistant Axis制約は、organの影響のうちモデルのアイデンティティ方向に沿った成分を射影して除去することでこれに対処する。重要なのは、organ寄与を完全に除去するのではなく——キャリブレーションされたバランスの取れた応答行動をエンコードする「自分自身である」次元のみを制約することである。organからの直交寄与は制約なしに通過し、最適設定（$\lambda{=}0.01$, L24--27）がベースモデルを**超過**する理由を説明する：organが真にタスク関連のシグナルを提供し、制約がそれを通過させるのである。

### 6.4 タスク-能力ミスマッチ

JNLI実験からの重要な観察として、日本語organは単独ではJNLI精度を改善しない（48.0% vs. ベース68.0%）。これは移植の失敗ではなく、**タスク-能力ミスマッチ**である：JNLIは主に日本語テキスト上の論理推論をテストし、日本語の言語能力をテストするのではない。日本語organは言語的能力（語彙、文法、流暢さ）を提供するが、推論能力は提供しない。この区別はorgan選択に含意を持つ——タスクに適切なorganは、タスクが要求する**認知能力**に合致する必要があり、**言語**や**ドメイン**だけでは不十分である。

### 6.5 モデル拡張の民主化

最も重要な実用的含意はアクセシビリティである。本手法により：

- ノートPCを持つ研究者が7Bモデルを1分以内に拡張可能
- 小さなファイル（organ1つあたり約100MB）として共有可能なプラグ・アンド・プレイの能力モジュール
- 異アーキテクチャ移植：14B〜34Bモデルからのorganを学習済み次元ブリッジを介して7Bホストに移植可能
- 高コストな再トレーニングなしにorganの組み合わせを実験可能

モデルカスタマイズの障壁を「GPUクラスタが必要」から「ノートPCがあれば十分」に引き下げる。

### 6.6 制限事項

1. **評価規模**: 主要コード生成結果はseed毎に50問のHumanEvalに基づく。3-seed反復（計150評価）により一貫した正のorgan効果（+1.3pp simple, +2.7pp reasoning）を確認したが、プールされた二項検定は非有意（p=0.38）のままである。クロスベンチマーク評価（§5.13）のMMLU-STEM、JCommonsenseQA、MBPPではより大きな効果サイズを確認したが（MBPP +8pp、JComQA +10pp）、全評価は単一seed（42）による50〜200問で実施している。
2. **単一ホストモデル**: Qwen2.5-7B-Instructのみで評価。他のアーキテクチャ（Llama, Mistral）への汎化は未検証。
3. **主要NLIベンチマークとしてのJNLI**: 50サンプルのサブセットは限られた統計的検出力を提供する。確信度バイアスのパターンは全条件で一貫しているが、個々の精度値には固有のノイズマージンがある。
4. **Axis制約の汎用性**: アシスタント軸はモデル固有であり、1回限りの抽出ステップ（約70分）を必要とする。同じ軸が異なるタスクタイプ間で効果的に制約するかは未検証。
5. **日本語品質の自動メトリックの欠如**: 信頼できる自動メトリックの欠如により、日本語生成品質（流暢さ、自然さ）の評価ができなかった。文法的に正しい日本語は自然な日本語と等価ではなく、多くのネイティブスピーカーは文法的に不完全だが自然なテキストを生成する——この区別は現在のメトリックでは捕捉できない。
6. **推論オーバーヘッド**: 各organが追加のMLP層のフォワードパスを追加し、推論レイテンシがorgan1つあたり約10〜15%増加。

### 6.7 今後の研究

1. **自動制約チューニング**: タスクごとの最適な $\lambda$ とレイヤー範囲の学習。小規模バリデーションセットの利用が考えられる。
2. **Organライブラリ**: 確信度バイアスプロファイルを文書化した共有可能なorganリポジトリの構築。
3. **タスク対応型organルーティング**: クロスベンチマーク評価（§5.13）により、全organの一律適用が無関係タスクでソフト干渉を引き起こすことが判明した。MoEルーティングに類似した学習可能なゲーティング機構——入力に基づきどのorganを活性化するかを選択——により、対象タスクでのorgan効果を維持しつつ、それ以外でのホスト劣化を回避できる可能性がある。これは、Axis制約が解決ではなくトレードオフするに留まる、能力向上と知識保持の根本的な緊張関係に対処するものである。
4. **移植のスケーリング則**: organ効果がホストおよびドナーのモデルサイズとどのようにスケールするかの理解。
5. **日本語生成の評価**: 日本語テキストの自然さに関するhuman-in-the-loopまたは学習ベースのメトリックの開発。現在の自動評価の根本的制限に対処する。

---

## 7. 結論（Conclusion）

本論文では、加算的organ挿入によるLLM能力拡張のための軽量かつアクセシブルな手法であるHamburger Transplantationを提示した。専門モデルから凍結MLP層を抽出し、薄いstitching layerを介してホストモデルに接続することで、コンシューマーハードウェア上でわずか30〜60秒のトレーニングで測定可能な能力改善を達成する。

本研究の調査は、加算的移植の可能性と落とし穴の両方を明らかにした。ポジティブな側面として：デュアルorgan挿入はHumanEvalで一貫した+4ポイントの改善をもたらし、Code OrganはMBPPで+8pp、Japanese OrganはJCommonsenseQAで+10ppを達成し、クロスベンチマーク上の真の能力転移を確認した。異スケール移植はホストの隠れ次元の2倍までのモデルからのorganを可能にする。

慎重さを要する側面として、2つの異なる障害モードを特定した。第一に、**確信度バイアス**：organ挿入がNLIタスクにおける中立予測を系統的に抑制し、3クラス分布を2クラスに縮退させる。第二に、**ソフト干渉**：マルチorgan挿入がベースパラメータ凍結にもかかわらず、MMLU-STEMを最大-7.5pp劣化させる——加算的寄与が重みを変更することなくホストの活性化ランドスケープを摂動させうることを示す。

提案した解決策——Assistant Axis制約付きトレーニング——は、確信度バイアスを解消しホスト知識を回復させる（MMLU-STEMがベースライン水準に復帰）が、代償を伴う：制約が保持すべきorgan効果そのものを抑制し、JCommonsenseQAをベースモデル以下に低下させる（78% vs. 82%）。アブレーション研究によりJNLIでベースモデルを超過するスイートスポット（$\lambda{=}0.01$, L24--27, 72.0% vs. 68.0%）を特定したが、クロスベンチマーク評価はこれが普遍的ではなくタスク固有であることを示す。

より広い教訓は、加算的移植には1つではなく2つの保持課題が存在するということである：**能力保持**（残差接続により維持）と**分布保持**（organ寄与により破壊）。Axis制約はある形態の保持を別の形態と交換する。この根本的な緊張関係の解消——例えば入力条件付きorganゲーティングを通じて——が、モジュラーニューラルアーキテクチャの中心的な未解決問題である。

全実験は単一のMacBook Pro（M4 Pro, 24GB）上で実施され、GPU クラスタなしでneural organ transplantationに関する意義のある研究が可能であることを示す。

---

## 参考文献

1. Bansal, Y., Nakkiran, P., and Barak, B. (2021). Revisiting Model Stitching to Compare Neural Representations. *NeurIPS*.
2. Chen, M., et al. (2021). Evaluating Large Language Models Trained on Code. *arXiv:2107.03374*.
3. Csiszárik, A., et al. (2021). Similarity and Matching of Neural Network Representations. *NeurIPS*.
4. Dettmers, T., et al. (2023). QLoRA: Efficient Finetuning of Quantized Language Models. *NeurIPS*.
5. Fedus, W., Zoph, B., and Shazeer, N. (2022). Switch Transformers. *JMLR*, 23(120):1-39.
6. Guo, D., et al. (2025). DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via RL. *arXiv:2501.12948*.
7. Hu, E.J., et al. (2022). LoRA: Low-Rank Adaptation of Large Language Models. *ICLR*.
8. Hui, B., et al. (2024). Qwen2.5-Coder Technical Report. *arXiv:2409.12186*.
9. Ilharco, G., et al. (2023). Editing Models with Task Arithmetic. *ICLR*.
10. Jawahar, G., Sagot, B., and Seddah, D. (2019). What Does BERT Learn about the Structure of Language? *ACL*.
11. Kirkpatrick, J., et al. (2017). Overcoming catastrophic forgetting in neural networks. *PNAS*, 114(13):3521-3526.
12. Komatsuzaki, A., et al. (2023). Sparse Upcycling: Training MoE from Dense Checkpoints. *ICLR*.
13. Kurihara, K., et al. (2022). JGLUE: Japanese General Language Understanding Evaluation. *LREC*.
14. Liu, S.-Y., et al. (2024). DoRA: Weight-Decomposed Low-Rank Adaptation. *ICML*.
15. Men, X., et al. (2024). ShortGPT: Layers in Large Language Models are More Redundant Than You Expect. *arXiv:2403.03853*.
16. Qwen Team (2024). Qwen2.5 Technical Report. *arXiv:2412.15115*.
17. Schönemann, P.H. (1966). A generalized solution of the orthogonal procrustes problem. *Psychometrika*, 31(1):1-10.
18. Shazeer, N. (2020). GLU Variants Improve Transformer. *arXiv:2002.05202*.
19. Shazeer, N., et al. (2017). Outrageously Large Neural Networks: The Sparsely-Gated MoE Layer. *ICLR*.
20. Tenney, I., Das, D., and Pavlick, E. (2019). BERT Rediscovers the Classical NLP Pipeline. *ACL*.
21. Wortsman, M., et al. (2022). Model soups. *ICML*.
22. Yadav, P., et al. (2023). TIES-Merging: Resolving Interference When Merging Models. *NeurIPS*.
23. Al-Zuraiqi, A. (2026). Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models. *arXiv:2601.13580*.
24. Yu, L., et al. (2024). Language Models are Super Mario. *ICML*.

---

## 付録A: 問題レベルの詳細結果

HumanEval 10問サブセット（seed=42）の問題レベル結果：

| Task ID | ベース | Code 1ep | デュアル+推論 | 難易度 |
|---------|--------|----------|-------------|--------|
| HumanEval/163 | ✓ | ✗ | ✗ | トリッキー（「偶数桁」） |
| HumanEval/28 | ✓ | ✓ | ✓ | 標準 |
| HumanEval/6 | ✓ | ✓ | ✓ | 標準 |
| HumanEval/70 | ✓ | ✓ | ✓ | 標準 |
| HumanEval/62 | ✓ | ✓ | ✓ | 標準 |
| HumanEval/57 | ✓ | ✓ | ✓ | 標準 |
| HumanEval/35 | ✓ | ✓ | ✓ | 標準 |
| HumanEval/26 | ✓ | ✗ | ✓ | トリッキー（意味論） |
| HumanEval/139 | ✓ | ✓ | ✓ | 標準 |
| HumanEval/22 | ✗ | ✓ | ✓ | 標準 |
| **合計** | **8/10** | **8/10** | **9/10** | |

## 付録B: 再現ガイド

全実験は24GB以上のRAMを持つコンシューマーノートPCで再現可能：

```bash
# ステップ1: インストール
pip install -e .

# ステップ2: 重みダウンロード
python scripts/download_weights.py --repo your-username/hamburger-transplant-weights

# ステップ3: Stitching layerのトレーニング（各30秒）
python scripts/train_math_stitching.py
python scripts/train_code_stitching.py

# ステップ4: 公平な4条件ベンチマーク（約80分）
python scripts/benchmark_fair.py --num-problems 50
```

コードとorgan重みは以下で利用可能: `https://github.com/tatsuru-okada-business/hamburger-transplant-public`
